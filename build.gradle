/*
 * Copyright (c) 2007-2015 Concurrent, Inc. All Rights Reserved.
 *
 * Project and contact information: http://www.cascading.org/
 *
 * This file is part of the Cascading project.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import java.text.SimpleDateFormat
import org.apache.tools.ant.filters.ReplaceTokens

apply from: 'etc/version.gradle'
apply from: 'etc/properties.gradle'
apply from: 'etc/s3Upload.gradle'

buildscript {
  repositories {
    mavenLocal()
    mavenCentral()
    maven { url 'http://repo.springsource.org/plugins-release' }
  }
  dependencies {
    classpath 'org.springframework.build.gradle:propdeps-plugin:0.0.5'
    classpath 'eu.appsatori:gradle-fatjar-plugin:0.2'
  }
}

// gives 'provided' scope for hadoop
configure( allprojects ) {
  apply plugin: 'propdeps'
  apply plugin: 'propdeps-maven'
  apply plugin: 'propdeps-idea'
  apply plugin: 'propdeps-eclipse'
  apply plugin: 'fatjar'
}

repositories {
  mavenLocal()
  mavenCentral()
  maven{ url 'http://conjars.org/repo/' }
}

ext.cascadingVersion = '2.7.0-wip-+'
ext.hadoopVersion = '1.2.1'
ext.hadoop2Version = '2.4.1'
ext.cascadingChanging = cascadingVersion.endsWith( ' -dev' );
ext.buildDate = new SimpleDateFormat( "yyyyMMdd" ).format( new Date() )
ext.buildTimestamp = new SimpleDateFormat( "yyyy-MM-dd HH:mm:ss" ).format( new Date() )
ext.tarBaseName = "${rootProject.name}-${buildDate}"
ext.finalTarName = "${tarBaseName}.tgz"

subprojects {
  ext.jarName = "${project.name}-${buildDate}.jar"
  apply plugin: 'java'
  apply plugin: 'maven'
  apply plugin: 'idea'
  apply plugin: 'eclipse'
  apply from: "${rootDir}/etc/testing.gradle"

  repositories{
    mavenLocal()
    mavenCentral()
    maven{ url 'http://conjars.org/repo/' }
  }

  configurations {
    testArtifacts {
      extendsFrom testRuntime
    }
  }

  dependencies {
    testCompile group: 'junit', name: 'junit', version: "4.11"
  }
  test {
    exclude '**/*TestCase*'
  }

  task testsJar( type: Jar, dependsOn: testClasses ) {
    from sourceSets.test.output
    classifier = 'tests'
  }

  task testSourcesJar( type: Jar, dependsOn: classes ) {
    from sourceSets.test.allSource
    classifier = 'test-sources'
  }


  artifacts {
    testArtifacts testsJar
    testArtifacts testSourcesJar
  }
}

allprojects {
  idea {
    module {
      downloadJavadoc = true
      downloadSources = true
    }
  }

  eclipse {
    classpath {
      defaultOutputDir = file( 'build' )
      downloadSources = true
      downloadJavadoc = true
    }
  }
}

task distCopy( type: Copy, dependsOn: jar ) {

  into "${buildDir}/dist/${archivesBaseName}-${buildDate}"

  from 'README.md'
  from 'apl.txt'
  from( 'src/main/shell' ) { into 'bin' }

  from( project ( ":load-hadoop" ).fatJar ) { into 'platform/hadoop/' }
  from( project ( ":load-hadoop2-mr1" ).fatJar ) { into 'platform/hadoop2-mr1/' }
  from( project ( ":load-local" ).fatJar ) { into 'platform/local/' }
  from( "load-docs/build/asciidoc" ) {into 'docs'}
}

distCopy.dependsOn( [":load-docs:asciidoctor", ":load-hadoop:fatJar", ":load-hadoop2-mr1:fatJar", "load-local:fatJar" ] )


task buildTarball( type: Tar, dependsOn: distCopy ) {
  baseName = "${tarBaseName}"
  destinationDir = new File( "${s3UploadArtifacts.source}" )
  compression = Compression.GZIP
  from( "build/dist" )
}

task packageDist( dependsOn: buildTarball ) << {
  file( "${s3UploadArtifacts.source}/latest.txt" ).write( "http://${s3UploadArtifacts.destination}${finalTarName}" )
  //file( "${s3UploadArtifacts.source}/latest-sha1.txt" ).write( "http://${s3UploadArtifacts.destination}${finalTarName}.sha1" )
  //file( "${s3UploadArtifacts.source}/latest-md5.txt" ).write( "http://${s3UploadArtifacts.destination}${finalTarName}.md5" )
  file( "${s3UploadArtifacts.source}/latest-hadoop-jar.txt" ).write( "http://${s3UploadArtifacts.destination}${project( 'load-hadoop').jarName}" )
  file( "${s3UploadArtifacts.source}/latest-hadoop2-mr1-jar.txt" ).write( "http://${s3UploadArtifacts.destination}${project( 'load-hadoop2-mr1').jarName}" )
  copy {
    from ( project( ":load-hadoop" ).fatJar )
    into( "${s3UploadArtifacts.source}" )
  }
  copy {
    from ( project( ":load-hadoop2-mr1" ).fatJar )
    into( "${s3UploadArtifacts.source}" )
  }
  copy {
    from( "src/main/shell/util/install-load.sh" )
      filter( ReplaceTokens, tokens: [
              'location': project.s3Bucket.toString(),
              'majorVersion': majorVersion.toString()
      ] )
    into( "${s3UploadArtifacts.source}" )
  }
}
