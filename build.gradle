/*
 * Copyright (c) 2007-2012 Concurrent, Inc. All Rights Reserved.
 *
 * Project and contact information: http://www.concurrentinc.com/
 */

import java.text.SimpleDateFormat

apply plugin: 'java'
apply plugin: 'idea'
apply plugin: 'eclipse'

project.archivesBaseName = 'load'

if( project.properties[ 'teamcity' ] ) // make them system properties
  System.properties.putAll( project.properties[ 'teamcity' ] )

if( System.properties[ 'aws.properties' ] )
{
  file( System.properties[ 'aws.properties' ] ).withReader { reader ->
    def awsProperties = new Properties()
    awsProperties.load( reader )
    System.properties.putAll( awsProperties )
  }
}

ext.timestamp = new SimpleDateFormat( "yyyyMMdd" ).format( new Date() )

configurations {
  sshAntTask
  s3AntTask
}

dependencies {
  sshAntTask 'org.apache.ant:ant-jsch:1.7.1', 'jsch:jsch:0.1.29'
  s3AntTask 'thirdparty:awstasks:0.3'
}

repositories {
  mavenLocal()
  mavenCentral()
  mavenRepo name: 'conjars', url: 'http://conjars.org/repo/'
  mavenRepo name: 'apache', url: 'https://repository.apache.org/content/repositories/releases/'
}

dependencies {
  compile( 'cascading:cascading-core:2.0.+' ) { exclude group: 'log4j' }
  compile( 'cascading:cascading-hadoop:2.0.+' ) { transitive = false }
  compile( 'cascading:cascading-local:2.0.+' ) { transitive = false }
  compile( 'org.apache.hadoop:hadoop-core:1.0.+' ) { exclude group: 'ant' }
  compile( 'net.sf.jopt-simple:jopt-simple:4.3' )
  compile( 'log4j:log4j:1.2.16' )

  testCompile( 'cascading:cascading-test:2.0.+' )
  testCompile( 'org.apache.hadoop:hadoop-test:1.0.+' )
  testCompile( 'junit:junit:4.8.+' )
}

sourceSets {
  main {
    java.srcDir 'src/java'
    resources.srcDir 'src/resources'
  }

  test {
    java.srcDir 'src/test'
  }
}

task shellTest( type: Exec ) {
  commandLine = [ '/bin/sh', "${rootDir}/src/test/sh/helper/roundup.sh",
          "${rootDir}/src/test/sh/core/*_test.sh",
          "${rootDir}/src/test/sh/cascading/*_test.sh",
          "${rootDir}/src/test/sh/*_test.sh" ]
}

test {
  dependsOn 'shellTest'

  exclude '**/*TestCase*'
}

jar {
  description = "Assembles a Hadoop ready jar file"
  version = timestamp

  doFirst {

    def set = new HashSet()

    def deps = configurations.compile.resolvedConfiguration.firstLevelModuleDependencies.findAll { dep ->
      !dep.name.startsWith( 'org.apache.hadoop' ) && !dep.name.startsWith( 'log4j' )
    }.collect { dep ->
      dep.allModuleArtifacts.collect {
        it.file
      }
    }

    deps.each { col -> set.addAll( col )}

    into( 'lib' ) {
      from( set )
    }
  }

  manifest {
    attributes( "Main-Class": "cascading/load/Main" )
    attributes( "Build-Date": "${timestamp}" )
  }
}

task distCopy( type: Copy, dependsOn: jar ) {

  into "${buildDir}/dist/${archivesBaseName}-${timestamp}"

  from 'README.md'
  from 'COMMANDS.md'
  from 'apl.txt'
  from( 'bin' ) {into 'bin'}

  from "$buildDir/libs"
}

task dist( type: Tar, dependsOn: distCopy ) {

  compression = "GZIP"
  version = timestamp

  from "${buildDir}/dist/"
}

task s3Upload( dependsOn: dist ) {

  ext.awsAccessId = System.properties[ 'publish.aws.accessId' ]
  ext.awsSecretKey = System.properties[ 'publish.aws.secretKey' ]
  ext.s3Bucket = System.properties[ 'publish.bucket' ]

  ext.remotePath = 'load/2.0/'
}

s3Upload << {

  def latestJarPath = new File( buildDir, 'latest-jar.txt' )

  latestJarPath.write( "http://${s3Bucket}/${remotePath}${jar.archivePath.name}" )

  def latestPath = new File( buildDir, 'latest.txt' )

  latestPath.write( "http://${s3Bucket}/${remotePath}${dist.archivePath.name}" )

  ant.taskdef( name: 's3Upload', classname: 'dak.ant.taskdefs.S3Upload',
          classpath: configurations.s3AntTask.asPath )

  ant.s3Upload( verbose: 'true', accessId: awsAccessId, secretKey: awsSecretKey,
          bucket: s3Bucket, prefix: remotePath, publicRead: 'true' ) {
    fileset( file: dist.archivePath )
    fileset( file: jar.archivePath )
    fileset( file: latestJarPath )
    fileset( file: latestPath )
  }

  latestJarPath.delete()
  latestPath.delete()
}

task sitePublish( dependsOn: s3Upload ) << {

  def publishBucket = System.properties[ 'publish.bucket' ]
  def publishDownloadPath = System.properties[ 'publish.download.path' ]
  def publishPort = !System.properties[ 'publish.port' ] ? '22' : System.properties[ 'publish.port' ]
  def publishKeyFile = System.properties[ 'publish.keyfile' ]

  ant.taskdef( name: 'scp', classname: 'org.apache.tools.ant.taskdefs.optional.ssh.Scp',
          classpath: configurations.sshAntTask.asPath )

  def latestPath = new File( buildDir, 'latest.txt' )

  latestPath.write( "http://${publishBucket}/load/2.0/${dist.archivePath.name}" )

  def remoteToFile = "${publishDownloadPath}/load/2.0/latest.txt"

  ant.scp( file: latestPath, remoteToFile: remoteToFile,
          keyfile: publishKeyFile, passphrase: '', port: publishPort, trust: 'true' )

  latestPath.delete()

  def latestJarPath = new File( buildDir, 'latest-jar.txt' )

  latestJarPath.write( "http://${publishBucket}/load/2.0/${jar.archivePath.name}" )

  def remoteToJarFile = "${publishDownloadPath}/load/2.0/latest-jar.txt"

  ant.scp( file: latestJarPath, remoteToFile: remoteToJarFile,
          keyfile: publishKeyFile, passphrase: '', port: publishPort, trust: 'true' )

  latestJarPath.delete()
}
