/*
 * Copyright (c) 2007-2014 Concurrent, Inc. All Rights Reserved.
 *
 * Project and contact information: http://www.cascading.org/
 *
 * This file is part of the Cascading project.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import java.text.SimpleDateFormat
import org.apache.tools.ant.filters.ReplaceTokens

apply from: 'etc/version.gradle'
apply from: 'etc/properties.gradle'
apply from: 'etc/s3Upload.gradle'

buildscript {
  repositories {
    mavenLocal()
    mavenCentral()
    maven { url 'http://repo.springsource.org/plugins-release' }
  }
  dependencies {
    classpath 'org.springframework.build.gradle:propdeps-plugin:0.0.4'
    classpath 'eu.appsatori:gradle-fatjar-plugin:0.2-rc1'
  }
}

// gives 'provided' scope for hadoop
configure( allprojects ) {
  apply plugin: 'propdeps'
  apply plugin: 'propdeps-maven'
  apply plugin: 'propdeps-idea'
  apply plugin: 'propdeps-eclipse'
}

repositories {
  mavenLocal()
  mavenCentral()
  maven{ url 'http://conjars.org/repo/' }
}

ext.cascadingVersion = '2.5.2'
ext.hadoopVersion = '1.2.1'
ext.hadoop2Version = '2.2.0'
ext.cascadingChanging = cascadingVersion.endsWith( ' -dev' );
ext.buildDate = new SimpleDateFormat( "yyyyMMdd" ).format( new Date() )
ext.buildTimestamp = new SimpleDateFormat( "yyyy-MM-dd HH:mm:ss" ).format( new Date() )

subprojects {
  ext.jarName = "${project.name}-${buildDate}.jar"
  apply plugin: 'java'
  apply plugin: 'maven'
  apply plugin: 'idea'
  apply plugin: 'eclipse'

  repositories{
    mavenLocal()
    mavenCentral()
    mavenRepo name: 'conjars', url: 'http://conjars.org/repo/'
  }

  dependencies {
    testCompile group: 'junit', name: 'junit', version: "4.11"
  }
  test {
    exclude '**/*TestCase*'
  }
}

task distCopy( type: Copy, dependsOn: jar ) {

  into "${buildDir}/dist/${archivesBaseName}-${buildDate}"

  from 'README.md'
  from 'apl.txt'
  from( 'src/main/shell' ) { into 'bin' }

  from( "load-hadoop/build/libs" ) { into 'platform/hadoop/' }
  from( "load-hadoop2-mr1/build/libs" ) { into 'platform/hadoop2mr1/' }
  from( "load-docs/build/asciidoc" ) {into 'docs'}
}

distCopy.dependsOn( [":load-docs:asciidoctor", ":load-hadoop:fatJar", ":load-hadoop2-mr1:fatJar" ] )

task dist( type: Tar, dependsOn: distCopy ) {

  compression = "GZIP"
  version = buildDir

  from "${buildDir}/dist/"
}

/*task s3Upload( dependsOn: dist ) {*/

  //ext.awsAccessId = System.properties[ 'publish.aws.accessId' ]
  //ext.awsSecretKey = System.properties[ 'publish.aws.secretKey' ]
  //ext.s3Bucket = System.properties[ 'publish.bucket' ]

  //ext.remotePath = "load/${releaseMajor}/"
//}

//s3Upload << {

  //def latestJarPath = new File( buildDir, 'latest-jar.txt' )

  //latestJarPath.write( "http://${s3Bucket}/${remotePath}${jar.archivePath.name}" )

  //def latestPath = new File( buildDir, 'latest.txt' )

  //latestPath.write( "http://${s3Bucket}/${remotePath}${dist.archivePath.name}" )

  //ant.taskdef( name: 's3Upload', classname: 'dak.ant.taskdefs.S3Upload',
          //classpath: configurations.s3AntTask.asPath )

  //ant.s3Upload( verbose: 'true', accessId: awsAccessId, secretKey: awsSecretKey,
          //bucket: s3Bucket, prefix: remotePath, publicRead: 'true' ) {
    //fileset( file: dist.archivePath )
    //fileset( file: jar.archivePath )
    //fileset( file: latestJarPath )
    //fileset( file: latestPath )
  //}

  //latestJarPath.delete()
  //latestPath.delete()
/*}*/
